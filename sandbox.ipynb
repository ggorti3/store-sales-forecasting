{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deck/Documents/kaggle/store-sales-forecasting/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "train_df = train_df.rename({\"date\":\"ds\", \"sales\":\"y\"}, axis=1)\n",
    "\n",
    "oil_df = pd.read_csv(\"oil.csv\")\n",
    "oil_df = oil_df.rename({\"date\":\"ds\"}, axis=1)\n",
    "\n",
    "stores_df = pd.read_csv(\"stores.csv\")\n",
    "stores_dict = stores_df.set_index(\"store_nbr\").to_dict(\"index\")\n",
    "holidays_df = pd.read_csv(\"holidays_events.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df = test_df.rename({\"date\":\"ds\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate oil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_oil_df = pd.DataFrame({\"ds\":pd.date_range(train_df[\"ds\"].min(), test_df[\"ds\"].max()).astype(\"str\")})\n",
    "oil_df = blank_oil_df.merge(oil_df, how=\"left\", on=\"ds\")\n",
    "oil_df[\"dcoilwtico\"] = oil_df[\"dcoilwtico\"].interpolate(\"nearest\")\n",
    "oil_df.iloc[0, 1] = 93.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Holidays DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1367/2455401216.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  th_df[\"description\"] = th_df[\"description\"].str.removeprefix(\"Traslado \")\n"
     ]
    }
   ],
   "source": [
    "nth_df = holidays_df[holidays_df[\"transferred\"] == False]\n",
    "th_df = holidays_df[holidays_df[\"type\"] == \"Transfer\"]\n",
    "th_df[\"description\"] = th_df[\"description\"].str.removeprefix(\"Traslado \")\n",
    "all_holidays_df = pd.concat([nth_df, th_df], axis=0)[[\"date\", \"locale_name\", \"description\"]]\n",
    "all_holidays_df = all_holidays_df.rename({\"date\":\"ds\", \"description\":\"holiday\"}, axis=1)\n",
    "all_holidays_df[\"lower_window\"] = 0\n",
    "all_holidays_df[\"upper_window\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Additional Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(oil_df, how=\"left\", on=\"ds\")\n",
    "test_df = test_df.merge(oil_df, how=\"left\", on=\"ds\")\n",
    "\n",
    "# info cols\n",
    "train_df = train_df.merge(stores_df[[\"store_nbr\", \"cluster\"]], how=\"left\", on=\"store_nbr\")\n",
    "test_df = test_df.merge(stores_df[[\"store_nbr\", \"cluster\"]], how=\"left\", on=\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_counts = train_df.groupby([\"store_nbr\", \"family\"])[\"ds\"].agg(\"count\")\n",
    "\n",
    "stores = pd.unique(train_df[\"store_nbr\"])\n",
    "families = pd.unique(train_df[\"family\"])\n",
    "\n",
    "promotion_counts = train_df[[\"id\", \"onpromotion\"]].groupby(\"onpromotion\").agg(\"count\")\n",
    "num_promotions = promotion_counts.shape[0]\n",
    "\n",
    "states = pd.unique(stores_df[\"state\"])\n",
    "cities = pd.unique(stores_df[\"city\"])\n",
    "types = pd.unique(stores_df[\"type\"])\n",
    "cities_per_state = stores_df[[\"state\", \"city\"]].drop_duplicates().groupby(\"state\").agg(\"count\")\n",
    "stores_per_city = stores_df[[\"city\", \"store_nbr\"]].drop_duplicates().groupby(\"city\").agg(\"count\")\n",
    "stores_per_cluster = stores_df[[\"cluster\", \"store_nbr\"]].drop_duplicates().groupby(\"cluster\").agg(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset as necessary for implementation and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df[train_df[\"store_nbr\"] < 4]\n",
    "#test_df = test_df[test_df[\"store_nbr\"] < 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet: one model per store, family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msle(preds_df):\n",
    "    return np.mean((np.log(1 + preds_df[\"y\"].values) - np.log(1 + preds_df[\"yhat\"].values))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bottom_up(key_cols, train_df, stores_dict, all_holidays_df):\n",
    "    def fit(x_df):\n",
    "        store_nbrs = x_df[\"store_nbr\"].drop_duplicates()\n",
    "        states = [stores_dict[snbr][\"state\"] for snbr in store_nbrs]\n",
    "        cities = [stores_dict[snbr][\"city\"] for snbr in store_nbrs]\n",
    "        filter = (all_holidays_df[\"locale_name\"] == \"Ecuador\")\n",
    "        for s in states:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == s)\n",
    "        for c in cities:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == c)\n",
    "        h_df = all_holidays_df[filter]\n",
    "        h_df = h_df[[\"ds\", \"holiday\", \"lower_window\", \"upper_window\"]]\n",
    "\n",
    "        x_df = x_df.groupby(\"ds\").agg({\"y\":\"sum\", \"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "\n",
    "        model = Prophet(uncertainty_samples=0, holidays=h_df)\n",
    "        model.add_regressor(\"onpromotion\")\n",
    "        model.add_regressor(\"dcoilwtico\")\n",
    "\n",
    "        model.fit(x_df)\n",
    "        return model\n",
    "    \n",
    "    return train_df.groupby(key_cols).apply(fit).reset_index()\n",
    "\n",
    "def predict_bottom_up(test_df, models_df):\n",
    "    key_cols = models_df.columns[:-1].to_list()\n",
    "    def predict(x_df):\n",
    "        filter = pd.Series(models_df.shape[0] * [True])\n",
    "        for k in key_cols:\n",
    "            v = x_df[k].iloc[0]\n",
    "            filter = filter & (models_df[k] == v)\n",
    "        model = models_df[filter].iloc[0, -1]\n",
    "\n",
    "        x_df = x_df.groupby(\"ds\").agg({\"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "\n",
    "        return model.predict(x_df)\n",
    "\n",
    "    return test_df.groupby(key_cols).apply(predict).reset_index()\n",
    "\n",
    "def all_cross_validation(key_cols, train_df, stores_dict, all_holidays_df):\n",
    "    def cv(x_df):\n",
    "        store_nbrs = x_df[\"store_nbr\"].drop_duplicates()\n",
    "        states = [stores_dict[snbr][\"state\"] for snbr in store_nbrs]\n",
    "        cities = [stores_dict[snbr][\"city\"] for snbr in store_nbrs]\n",
    "        filter = (all_holidays_df[\"locale_name\"] == \"Ecuador\")\n",
    "        for s in states:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == s)\n",
    "        for c in cities:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == c)\n",
    "        h_df = all_holidays_df[filter]\n",
    "        h_df = h_df[[\"ds\", \"holiday\", \"lower_window\", \"upper_window\"]]\n",
    "\n",
    "        x_df = x_df.groupby(\"ds\").agg({\"y\":\"sum\", \"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "\n",
    "\n",
    "        model = Prophet(uncertainty_samples=0, holidays=h_df)\n",
    "        model.add_regressor(\"onpromotion\")\n",
    "        model.add_regressor(\"dcoilwtico\")\n",
    "        model.fit(x_df)\n",
    "        cv_df = cross_validation(model, initial='1460 days', period='56 days', horizon='16 days')\n",
    "        cv_df[\"yhat\"] = cv_df[\"yhat\"].clip(lower=0)\n",
    "        return cv_df.groupby(\"cutoff\").apply(msle).reset_index()\n",
    "\n",
    "    msles_df = train_df.groupby(key_cols).apply(cv).reset_index().rename({0:\"msle\"}, axis=1)\n",
    "    return np.mean(np.sqrt(msles_df.groupby(\"cutoff\")[\"msle\"].agg(\"mean\").values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportions(key_cols, support_cols, x_df):\n",
    "    x_df = x_df.groupby(key_cols + support_cols + [\"ds\"]).agg({\"y\":\"sum\", \"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "    agg_x_df = x_df.groupby(key_cols + [\"ds\"]).agg({\"y\":\"sum\"}).reset_index().rename({\"y\":\"agg_y\"}, axis=1)\n",
    "    x_df = x_df.merge(agg_x_df, how=\"left\", on=key_cols + [\"ds\"])\n",
    "    x_df[\"prop\"] = x_df.loc[:, [\"y\"]].where(x_df[\"agg_y\"] <= 0, x_df[\"y\"] / x_df[\"agg_y\"], axis=0)\n",
    "    return x_df.drop([\"y\", \"agg_y\"], axis=1)\n",
    "\n",
    "class VARModel():\n",
    "    def __init__(self, lag, support_cols):\n",
    "        self.lag = lag\n",
    "        self.support_cols = support_cols\n",
    "    \n",
    "    def fit(self, x_df, lmbda):\n",
    "        px_df = x_df.pivot(columns=self.support_cols, index=\"ds\", values=\"prop\").sort_index()\n",
    "        oil_df = x_df[[\"ds\", \"dcoilwtico\"]].drop_duplicates().sort_values(\"ds\")\n",
    "        # need to use loop to build design matrix\n",
    "        design_cols = []\n",
    "        for l in range(self.lag):\n",
    "            dc = px_df.iloc[l:(px_df.shape[0] - self.lag + l), :].values.flatten()\n",
    "            design_cols.append(dc)\n",
    "        design_cols.append(np.repeat(oil_df[\"dcoilwtico\"].values[(self.lag):], px_df.shape[1]))\n",
    "        X = np.stack(design_cols, axis=1)\n",
    "        y = px_df.iloc[self.lag:, :].values.flatten()\n",
    "        self.beta = lin_reg(X, y, lmbda)\n",
    "\n",
    "        self.px = px_df.values[-self.lag:, :].T\n",
    "        self.d = datetime.strptime(px_df.index[-1], \"%Y-%m-%d\").date() + timedelta(days=1)\n",
    "        self.support = px_df.columns\n",
    "    \n",
    "    def predict(self, test_oil_df, days):\n",
    "        test_oil_df = test_oil_df[[\"ds\", \"dcoilwtico\"]].drop_duplicates().set_index(\"ds\").sort_index()\n",
    "        ox = np.full((self.px.shape[0], 1), test_oil_df.loc[self.d.strftime(\"%Y-%m-%d\"), \"dcoilwtico\"])\n",
    "        bx = np.ones((self.px.shape[0], 1))\n",
    "        x = np.concatenate([bx, self.px, ox], axis=1)\n",
    "        d0 = self.d\n",
    "        out = []\n",
    "        for i in range(days):\n",
    "            if i > 0:\n",
    "                self.px = np.concatenate([self.px[:, 1:], y[:, np.newaxis]], axis=1)\n",
    "                self.d = self.d + timedelta(days=1)\n",
    "                ox = np.full((self.px.shape[0], 1), test_oil_df.loc[self.d.strftime(\"%Y-%m-%d\"), \"dcoilwtico\"])\n",
    "                bx = np.ones((self.px.shape[0], 1))\n",
    "                x = np.concatenate([bx, self.px, ox], axis=1)\n",
    "                \n",
    "            y = x @ self.beta\n",
    "            out.append(y)\n",
    "        ds = pd.date_range(start=d0.strftime(\"%Y-%m-%d\"), periods=days, freq=\"D\", inclusive=\"left\").repeat(self.px.shape[0])\n",
    "        pdf_dict = {\"ds\":ds}\n",
    "        if len(self.support_cols) == 1:\n",
    "            pdf_dict[self.support_cols[0]] = np.tile(self.support.to_numpy(), (days, ))\n",
    "        else:\n",
    "            for j, sc in enumerate(self.support_cols):\n",
    "                pdf_dict[sc] = np.tile(np.array([self.support[i][j] for i in range(len(self.support))]), (days, ))\n",
    "            pass\n",
    "        pdf_dict[\"yhat\"] = np.concatenate(out)\n",
    "        preds_df = pd.DataFrame(pdf_dict)\n",
    "        return preds_df\n",
    "\n",
    "\n",
    "def lin_reg(X, y, lmbda):\n",
    "    X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "    beta = np.linalg.solve(X.T @ X + lmbda * np.eye(X.shape[1]), X.T @ y)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_VAR(key_cols, support_cols, train_df):\n",
    "    prop_df = get_proportions(key_cols, support_cols, train_df)\n",
    "\n",
    "    def fit(x_df):\n",
    "        model = VARModel(lag=6, support_cols=support_cols)\n",
    "        model.fit(x_df, 0)\n",
    "        return model\n",
    "    return prop_df.groupby(key_cols).apply(fit).reset_index()\n",
    "\n",
    "\n",
    "def predict_VAR(key_cols, test_df, var_models_df):\n",
    "    def predict(x_df):\n",
    "        days = x_df[\"ds\"].drop_duplicates().shape[0]\n",
    "        filter = pd.Series(var_models_df.shape[0] * [True])\n",
    "        for k in key_cols:\n",
    "            v = x_df[k].iloc[0]\n",
    "            filter = filter & (var_models_df[k] == v)\n",
    "        model = var_models_df[filter].iloc[0, -1]\n",
    "        return model.predict(test_df, days)\n",
    "\n",
    "    return test_df.groupby(key_cols).apply(predict).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"cluster\"]\n",
    "support_cols = [\"store_nbr\", \"family\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster = 4\n",
    "# prop_df = get_proportions(key_cols, support_cols, train_df)\n",
    "# x_df = prop_df[prop_df[\"cluster\"] == cluster]\n",
    "\n",
    "# model = VARModel(lag=6, support_cols=support_cols)\n",
    "# model.fit(x_df, 0)\n",
    "# model.predict(test_df, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1367/2420157201.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return prop_df.groupby(key_cols).apply(fit).reset_index()\n",
      "/tmp/ipykernel_1367/2420157201.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  return test_df.groupby(key_cols).apply(predict).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>level_1</th>\n",
       "      <th>ds</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>yhat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>24</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>24</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>24</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.000182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>24</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.080710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>24</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>17</td>\n",
       "      <td>523</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>51</td>\n",
       "      <td>POULTRY</td>\n",
       "      <td>0.033805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>17</td>\n",
       "      <td>524</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>51</td>\n",
       "      <td>PREPARED FOODS</td>\n",
       "      <td>0.006683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>17</td>\n",
       "      <td>525</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>51</td>\n",
       "      <td>PRODUCE</td>\n",
       "      <td>0.231753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>17</td>\n",
       "      <td>526</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>51</td>\n",
       "      <td>SCHOOL AND OFFICE SUPPLIES</td>\n",
       "      <td>0.001161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>17</td>\n",
       "      <td>527</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>51</td>\n",
       "      <td>SEAFOOD</td>\n",
       "      <td>0.003318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28512 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster  level_1         ds  store_nbr                      family  \\\n",
       "0            1        0 2017-08-16         24                  AUTOMOTIVE   \n",
       "1            1        1 2017-08-16         24                   BABY CARE   \n",
       "2            1        2 2017-08-16         24                      BEAUTY   \n",
       "3            1        3 2017-08-16         24                   BEVERAGES   \n",
       "4            1        4 2017-08-16         24                       BOOKS   \n",
       "...        ...      ...        ...        ...                         ...   \n",
       "28507       17      523 2017-08-31         51                     POULTRY   \n",
       "28508       17      524 2017-08-31         51              PREPARED FOODS   \n",
       "28509       17      525 2017-08-31         51                     PRODUCE   \n",
       "28510       17      526 2017-08-31         51  SCHOOL AND OFFICE SUPPLIES   \n",
       "28511       17      527 2017-08-31         51                     SEAFOOD   \n",
       "\n",
       "           yhat  \n",
       "0      0.000162  \n",
       "1      0.000117  \n",
       "2      0.000182  \n",
       "3      0.080710  \n",
       "4      0.000117  \n",
       "...         ...  \n",
       "28507  0.033805  \n",
       "28508  0.006683  \n",
       "28509  0.231753  \n",
       "28510  0.001161  \n",
       "28511  0.003318  \n",
       "\n",
       "[28512 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_models_df = fit_VAR(key_cols, support_cols, train_df)\n",
    "predict_VAR(key_cols, test_df, var_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
