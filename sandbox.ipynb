{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "train_df = train_df.rename({\"date\":\"ds\", \"sales\":\"y\"}, axis=1)\n",
    "\n",
    "oil_df = pd.read_csv(\"oil.csv\")\n",
    "oil_df = oil_df.rename({\"date\":\"ds\"}, axis=1)\n",
    "\n",
    "stores_df = pd.read_csv(\"stores.csv\")\n",
    "stores_dict = stores_df.set_index(\"store_nbr\").to_dict(\"index\")\n",
    "holidays_df = pd.read_csv(\"holidays_events.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df = test_df.rename({\"date\":\"ds\"}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate oil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank_oil_df = pd.DataFrame({\"ds\":pd.date_range(train_df[\"ds\"].min(), test_df[\"ds\"].max()).astype(\"str\")})\n",
    "oil_df = blank_oil_df.merge(oil_df, how=\"left\", on=\"ds\")\n",
    "oil_df[\"dcoilwtico\"] = oil_df[\"dcoilwtico\"].interpolate(\"nearest\")\n",
    "oil_df.iloc[0, 1] = 93.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Holidays DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nth_df = holidays_df[holidays_df[\"transferred\"] == False]\n",
    "th_df = holidays_df[holidays_df[\"type\"] == \"Transfer\"]\n",
    "th_df[\"description\"] = th_df[\"description\"].str.removeprefix(\"Traslado \")\n",
    "all_holidays_df = pd.concat([nth_df, th_df], axis=0)[[\"date\", \"locale_name\", \"description\"]]\n",
    "all_holidays_df = all_holidays_df.rename({\"date\":\"ds\", \"description\":\"holiday\"}, axis=1)\n",
    "all_holidays_df[\"lower_window\"] = 0\n",
    "all_holidays_df[\"upper_window\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Additional Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(oil_df, how=\"left\", on=\"ds\")\n",
    "test_df = test_df.merge(oil_df, how=\"left\", on=\"ds\")\n",
    "\n",
    "# info cols\n",
    "train_df = train_df.merge(stores_df[[\"store_nbr\", \"cluster\"]], how=\"left\", on=\"store_nbr\")\n",
    "test_df = test_df.merge(stores_df[[\"store_nbr\", \"cluster\"]], how=\"left\", on=\"store_nbr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_counts = train_df.groupby([\"store_nbr\", \"family\"])[\"ds\"].agg(\"count\")\n",
    "\n",
    "stores = pd.unique(train_df[\"store_nbr\"])\n",
    "families = pd.unique(train_df[\"family\"])\n",
    "\n",
    "promotion_counts = train_df[[\"id\", \"onpromotion\"]].groupby(\"onpromotion\").agg(\"count\")\n",
    "num_promotions = promotion_counts.shape[0]\n",
    "\n",
    "states = pd.unique(stores_df[\"state\"])\n",
    "cities = pd.unique(stores_df[\"city\"])\n",
    "types = pd.unique(stores_df[\"type\"])\n",
    "cities_per_state = stores_df[[\"state\", \"city\"]].drop_duplicates().groupby(\"state\").agg(\"count\")\n",
    "stores_per_city = stores_df[[\"city\", \"store_nbr\"]].drop_duplicates().groupby(\"city\").agg(\"count\")\n",
    "stores_per_cluster = stores_df[[\"cluster\", \"store_nbr\"]].drop_duplicates().groupby(\"cluster\").agg(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset as necessary for implementation and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df[\"store_nbr\"] < 4]\n",
    "test_df = test_df[test_df[\"store_nbr\"] < 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prophet: one model per store, family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msle(preds_df):\n",
    "    return np.mean((np.log(1 + preds_df[\"y\"].values) - np.log(1 + preds_df[\"yhat\"].values))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bottom_up(key_cols, train_df, stores_dict, all_holidays_df):\n",
    "    def fit(x_df):\n",
    "        store_nbrs = x_df[\"store_nbr\"].drop_duplicates()\n",
    "        states = [stores_dict[snbr][\"state\"] for snbr in store_nbrs]\n",
    "        cities = [stores_dict[snbr][\"city\"] for snbr in store_nbrs]\n",
    "        filter = (all_holidays_df[\"locale_name\"] == \"Ecuador\")\n",
    "        for s in states:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == s)\n",
    "        for c in cities:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == c)\n",
    "        h_df = all_holidays_df[filter]\n",
    "        h_df = h_df[[\"ds\", \"holiday\", \"lower_window\", \"upper_window\"]]\n",
    "\n",
    "        x_df = x_df.groupby(\"ds\").agg({\"y\":\"sum\", \"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "\n",
    "        model = Prophet(uncertainty_samples=0, holidays=h_df)\n",
    "        model.add_regressor(\"onpromotion\")\n",
    "        model.add_regressor(\"dcoilwtico\")\n",
    "\n",
    "        model.fit(x_df)\n",
    "        return model\n",
    "    \n",
    "    return train_df.groupby(key_cols).apply(fit).reset_index()\n",
    "\n",
    "def predict_bottom_up(test_df, models_df):\n",
    "    key_cols = models_df.columns[:-1].to_list()\n",
    "    def predict(x_df):\n",
    "        filter = pd.Series(models_df.shape[0] * [True])\n",
    "        for k in key_cols:\n",
    "            v = x_df[k].iloc[0]\n",
    "            filter = filter & (models_df[k] == v)\n",
    "        model = models_df[filter].iloc[0, -1]\n",
    "\n",
    "        x_df = x_df.groupby(\"ds\").agg({\"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "\n",
    "        return model.predict(x_df)\n",
    "\n",
    "    return test_df.groupby(key_cols).apply(predict).reset_index()\n",
    "\n",
    "def all_cross_validation(key_cols, train_df, stores_dict, all_holidays_df):\n",
    "    def cv(x_df):\n",
    "        store_nbrs = x_df[\"store_nbr\"].drop_duplicates()\n",
    "        states = [stores_dict[snbr][\"state\"] for snbr in store_nbrs]\n",
    "        cities = [stores_dict[snbr][\"city\"] for snbr in store_nbrs]\n",
    "        filter = (all_holidays_df[\"locale_name\"] == \"Ecuador\")\n",
    "        for s in states:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == s)\n",
    "        for c in cities:\n",
    "            filter = filter | (all_holidays_df[\"locale_name\"] == c)\n",
    "        h_df = all_holidays_df[filter]\n",
    "        h_df = h_df[[\"ds\", \"holiday\", \"lower_window\", \"upper_window\"]]\n",
    "\n",
    "        x_df = x_df.groupby(\"ds\").agg({\"y\":\"sum\", \"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "\n",
    "\n",
    "        model = Prophet(uncertainty_samples=0, holidays=h_df)\n",
    "        model.add_regressor(\"onpromotion\")\n",
    "        model.add_regressor(\"dcoilwtico\")\n",
    "        model.fit(x_df)\n",
    "        cv_df = cross_validation(model, initial='1460 days', period='56 days', horizon='16 days')\n",
    "        cv_df[\"yhat\"] = cv_df[\"yhat\"].clip(lower=0)\n",
    "        return cv_df.groupby(\"cutoff\").apply(msle).reset_index()\n",
    "\n",
    "    msles_df = train_df.groupby(key_cols).apply(cv).reset_index().rename({0:\"msle\"}, axis=1)\n",
    "    return np.mean(np.sqrt(msles_df.groupby(\"cutoff\")[\"msle\"].agg(\"mean\").values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportions(key_cols, next_cols, x_df):\n",
    "    x_df = x_df.groupby(key_cols + next_cols + [\"ds\"]).agg({\"y\":\"sum\", \"onpromotion\":\"sum\", \"dcoilwtico\":\"first\"}).reset_index()\n",
    "    agg_x_df = x_df.groupby(key_cols + [\"ds\"]).agg({\"y\":\"sum\"}).reset_index().rename({\"y\":\"agg_y\"}, axis=1)\n",
    "    x_df = x_df.merge(agg_x_df, how=\"left\", on=key_cols + [\"ds\"])\n",
    "    x_df[\"prop\"] = x_df.loc[:, [\"y\"]].where(x_df[\"agg_y\"] <= 0, x_df[\"y\"] / x_df[\"agg_y\"], axis=0)\n",
    "    return x_df.drop([\"y\", \"agg_y\"], axis=1)\n",
    "\n",
    "class VARModel():\n",
    "    def __init__(self, lag, next_cols):\n",
    "        self.lag = lag\n",
    "        self.next_cols = next_cols\n",
    "    \n",
    "    def fit(self, x_df, lmbda):\n",
    "        px_df = x_df.pivot(columns=self.next_cols, index=\"ds\", values=\"prop\").reset_index().sort_values(\"ds\")\n",
    "        oil_df = x_df[[\"ds\", \"dcoilwtico\"]].drop_duplicates().sort_values(\"ds\")\n",
    "        # need to use loop to build design matrix\n",
    "        design_cols = []\n",
    "        for l in range(self.lag):\n",
    "            dc = px_df.iloc[l:(px_df.shape[0] - self.lag + l), :].values.flatten()\n",
    "            design_cols.append(dc)\n",
    "        design_cols.append(oil_df[\"dcoilwtico\"]).values[(self.lag):]\n",
    "        X = np.stack(design_cols, axis=1)\n",
    "        y = px_df.iloc[self.lag:, :].values.flatten()\n",
    "        self.beta = lin_reg(X, y, lmbda)\n",
    "    \n",
    "    def predict(self, agg_x_df, days):\n",
    "        x = agg_x_df.sort_values(\"ds\").values[-self.lag:]\n",
    "        out = []\n",
    "        for i in range(days):\n",
    "            y = np.concatenate([torch.ones((1, )), x]) @ self.beta\n",
    "            out.append(y)\n",
    "            x = np.concatenate([x[1:], np.array([y])])\n",
    "        ds = pd.date_range(start=agg_x_df[\"ds\"][-1], periods=days, freq=\"D\", inclusive=\"neither\")\n",
    "        preds_df = pd.DataFrame({\"ds\":ds, \"yhat\":out})\n",
    "        return preds_df\n",
    "\n",
    "\n",
    "def lin_reg(X, y, lmbda):\n",
    "    X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "    beta = np.linalg.solve(X.T @ X + lmbda * np.eye(X.shape[1]), X.T @ y)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 3\n",
    "key_cols = [\"cluster\"]\n",
    "next_cols = [\"family\"]\n",
    "lag = 5\n",
    "prop_df = get_proportions(key_cols, next_cols, train_df)\n",
    "x_df = prop_df[prop_df[\"cluster\"] == cluster].drop(\"cluster\")\n",
    "\n",
    "model = VARModel(lag, next_cols)\n",
    "model.fit(x_df, lmbda=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"cluster\", \"family\"]\n",
    "next_cols = [\"family\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_df = get_proportions(key_cols, next_cols, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_cols = [\"store_nbr\", \"family\"]\n",
    "models_df = fit_bottom_up(key_cols, train_df, stores_dict, all_holidays_df)\n",
    "preds_df = predict_bottom_up(test_df, models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = all_cross_validation(key_cols, train_df, stores_dict, all_holidays_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
